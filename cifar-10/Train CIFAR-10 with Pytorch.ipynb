{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在如何使CIFAR-10测试集的分类准确率从40%提升到90%\n",
    "本文将依次在两层全连接网络，三层卷积网络，自定义多层卷积网络，经典网络（ResNet）上训练和验证cifar-10，见证测试集准确率是如何从40%提升到90%的。通过本文可以对Pytorch下如何构建网络，训练网络和调优有较清晰的认识。<br>\n",
    "注意，Pytorch model zoo中的resnet模型直接使用会报错，因此需要自己实现一个resnet，本文引用了CSDN上 [以梦为马_Sun](https://blog.csdn.net/sunqiande88/article/details/80100891)的实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import copy\n",
    "from resnet import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 从训练集的50000个样本中，取49000个作为训练集，剩余1000个作为验证集\n",
    "NUM_TRAIN = 49000\n",
    "\n",
    "# 数据预处理，减去cifar-10数据均值\n",
    "transform_normal = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465),(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "# 数据增强\n",
    "transform_aug = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# 加载训练集\n",
    "cifar10_train = dset.CIFAR10('./dataset', train=True, download=True, transform=transform_normal)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "# 加载验证集\n",
    "cifar10_val = dset.CIFAR10('./dataset', train=True, download=True, transform=transform_normal)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "# 加载测试集\n",
    "cifar10_test = dset.CIFAR10('./dataset', train=False, download=True, transform=transform_normal)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指定运行环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "dtype = torch.float32\n",
    "print_every = 100\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "定义一个pipeline针对不同的模型和优化器进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 验证模型在验证集或者测试集上的准确率\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()   # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _,preds = scores.max(1)\n",
    "            num_correct += (preds==y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 *acc ))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, epochs=1, scheduler=None):\n",
    "    '''\n",
    "    Parameters:\n",
    "    - model: A Pytorch Module giving the model to train.\n",
    "    - optimizer: An optimizer object we will use to train the model\n",
    "    - epochs: A Python integer giving the number of epochs to train\n",
    "    Returns: best model\n",
    "    '''\n",
    "    best_model_wts = None\n",
    "    best_acc = 0.0\n",
    "    model = model.to(device=device) # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        for t,(x,y) in enumerate(loader_train):\n",
    "            model.train()   # set model to training mode\n",
    "            x = x.to(device, dtype=dtype)\n",
    "            y = y.to(device, dtype=torch.long)\n",
    "            \n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print('Epoch %d, loss=%.4f' % (e, loss.item()))\n",
    "        acc = check_accuracy(loader_val, model)\n",
    "        if acc > best_acc:\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            best_acc = acc\n",
    "    print('best_acc:',best_acc)\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型构建\n",
    "pytorch构建网络的方式有很多，这里采用最简便的Sequential方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型一：两层全连接网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before flattening:  tensor([[[[ 0,  1],\n",
      "          [ 2,  3],\n",
      "          [ 4,  5]]],\n",
      "\n",
      "\n",
      "        [[[ 6,  7],\n",
      "          [ 8,  9],\n",
      "          [10, 11]]]])\n",
      "After flattening:  tensor([[ 0,  1,  2,  3,  4,  5],\n",
      "        [ 6,  7,  8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "# 为了进行全连接，需要将三维的图像数据转换为向量，因此需要自定义flatten函数，并进一步封装为Module\n",
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "# 两层全连接网络\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "def test_flatten():\n",
    "    x = torch.arange(12).view(2, 1, 3, 2)\n",
    "    print('Before flattening: ', x)\n",
    "    print('After flattening: ', flatten(x))\n",
    "\n",
    "test_flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=1.4780\n",
      "Checking accuracy on validation set\n",
      "Got 416 / 1000 correct (41.60)\n",
      "Epoch 1, loss=1.5226\n",
      "Checking accuracy on validation set\n",
      "Got 446 / 1000 correct (44.60)\n",
      "Epoch 2, loss=1.4634\n",
      "Checking accuracy on validation set\n",
      "Got 487 / 1000 correct (48.70)\n",
      "Epoch 3, loss=1.8989\n",
      "Checking accuracy on validation set\n",
      "Got 432 / 1000 correct (43.20)\n",
      "Epoch 4, loss=1.1913\n",
      "Checking accuracy on validation set\n",
      "Got 463 / 1000 correct (46.30)\n",
      "Epoch 5, loss=1.6002\n",
      "Checking accuracy on validation set\n",
      "Got 461 / 1000 correct (46.10)\n",
      "Epoch 6, loss=2.2539\n",
      "Checking accuracy on validation set\n",
      "Got 419 / 1000 correct (41.90)\n",
      "Epoch 7, loss=1.7929\n",
      "Checking accuracy on validation set\n",
      "Got 474 / 1000 correct (47.40)\n",
      "Epoch 8, loss=1.7705\n",
      "Checking accuracy on validation set\n",
      "Got 465 / 1000 correct (46.50)\n",
      "Epoch 9, loss=2.1885\n",
      "Checking accuracy on validation set\n",
      "Got 453 / 1000 correct (45.30)\n",
      "best_acc: 0.487\n",
      "Checking accuracy on test set\n",
      "Got 4685 / 10000 correct (46.85)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4685"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_size = 4000\n",
    "learning_rate = 1e-2\n",
    "two_fc_model = nn.Sequential(\n",
    "    Flatten(),\n",
    "    nn.Linear(3*32*32, hidden_layer_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_layer_size, 10)\n",
    ")\n",
    "optimizer_two_fc = optim.SGD(two_fc_model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "best_two_fc = train_model(two_fc_model, optimizer_two_fc, 10)\n",
    "check_accuracy(loader_test, best_two_fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在两层全连接网络上训练10代，最好的验证集表现为48.7%，而在测试集上的表现为46.85%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型二：三层卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=1.2659\n",
      "Checking accuracy on validation set\n",
      "Got 581 / 1000 correct (58.10)\n",
      "Epoch 1, loss=1.0249\n",
      "Checking accuracy on validation set\n",
      "Got 564 / 1000 correct (56.40)\n",
      "Epoch 2, loss=1.0673\n",
      "Checking accuracy on validation set\n",
      "Got 598 / 1000 correct (59.80)\n",
      "Epoch 3, loss=1.1520\n",
      "Checking accuracy on validation set\n",
      "Got 608 / 1000 correct (60.80)\n",
      "Epoch 4, loss=1.0127\n",
      "Checking accuracy on validation set\n",
      "Got 600 / 1000 correct (60.00)\n",
      "Epoch 5, loss=0.7969\n",
      "Checking accuracy on validation set\n",
      "Got 598 / 1000 correct (59.80)\n",
      "Epoch 6, loss=0.3082\n",
      "Checking accuracy on validation set\n",
      "Got 584 / 1000 correct (58.40)\n",
      "Epoch 7, loss=0.5596\n",
      "Checking accuracy on validation set\n",
      "Got 581 / 1000 correct (58.10)\n",
      "Epoch 8, loss=0.4902\n",
      "Checking accuracy on validation set\n",
      "Got 574 / 1000 correct (57.40)\n",
      "Epoch 9, loss=0.2449\n",
      "Checking accuracy on validation set\n",
      "Got 581 / 1000 correct (58.10)\n",
      "best_acc: 0.608\n",
      "Checking accuracy on test set\n",
      "Got 5991 / 10000 correct (59.91)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5991"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "three_conv_model = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, 5, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 16, 3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(16*32*32, 10)\n",
    ")\n",
    "optimizer_three_conv = optim.SGD(three_conv_model.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "best_three_conv = train_model(three_conv_model, optimizer_three_conv, 10)\n",
    "check_accuracy(loader_test, best_three_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在包含两个卷积层的网络上训练10代，最好的验证集表现为60.8%，而在测试集上的表现为59.91%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型三： 自定义多层卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=0.9281\n",
      "Checking accuracy on validation set\n",
      "Got 578 / 1000 correct (57.80)\n",
      "Epoch 1, loss=1.0054\n",
      "Checking accuracy on validation set\n",
      "Got 625 / 1000 correct (62.50)\n",
      "Epoch 2, loss=0.8731\n",
      "Checking accuracy on validation set\n",
      "Got 690 / 1000 correct (69.00)\n",
      "Epoch 3, loss=0.5354\n",
      "Checking accuracy on validation set\n",
      "Got 672 / 1000 correct (67.20)\n",
      "Epoch 4, loss=0.9772\n",
      "Checking accuracy on validation set\n",
      "Got 718 / 1000 correct (71.80)\n",
      "Epoch 5, loss=0.6140\n",
      "Checking accuracy on validation set\n",
      "Got 708 / 1000 correct (70.80)\n",
      "Epoch 6, loss=0.5491\n",
      "Checking accuracy on validation set\n",
      "Got 707 / 1000 correct (70.70)\n",
      "Epoch 7, loss=1.1112\n",
      "Checking accuracy on validation set\n",
      "Got 729 / 1000 correct (72.90)\n",
      "Epoch 8, loss=0.4567\n",
      "Checking accuracy on validation set\n",
      "Got 723 / 1000 correct (72.30)\n",
      "Epoch 9, loss=0.7924\n",
      "Checking accuracy on validation set\n",
      "Got 721 / 1000 correct (72.10)\n",
      "best_acc: 0.729\n",
      "Checking accuracy on test set\n",
      "Got 7223 / 10000 correct (72.23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7223"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "model_customize = nn.Sequential(\n",
    "    nn.Conv2d(3,16,3,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,stride=2),\n",
    "    nn.Conv2d(16,32,3,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,stride=2),\n",
    "    nn.Conv2d(32,32,3,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,stride=2),\n",
    "    Flatten(),\n",
    "    nn.Linear(32*4*4,32*4*4),\n",
    "    nn.Linear(32*4*4,32*2*2),\n",
    "    nn.Linear(32*2*2,10)\n",
    ")\n",
    "optimizer_customize = optim.SGD(model_customize.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "best_customize = train_model(model_customize, optimizer_customize, 10)\n",
    "check_accuracy(loader_test, best_customize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在包含更多卷积层和全连接层的网络上训练10代，最好的验证集表现为72.9%，而在测试集上的表现为72.23%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型四：预训练网络ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=0.7911\n",
      "Checking accuracy on validation set\n",
      "Got 629 / 1000 correct (62.90)\n",
      "Epoch 1, loss=0.8354\n",
      "Checking accuracy on validation set\n",
      "Got 738 / 1000 correct (73.80)\n",
      "Epoch 2, loss=0.7350\n",
      "Checking accuracy on validation set\n",
      "Got 777 / 1000 correct (77.70)\n",
      "Epoch 3, loss=0.2774\n",
      "Checking accuracy on validation set\n",
      "Got 791 / 1000 correct (79.10)\n",
      "Epoch 4, loss=0.2839\n",
      "Checking accuracy on validation set\n",
      "Got 816 / 1000 correct (81.60)\n",
      "Epoch 5, loss=0.2602\n",
      "Checking accuracy on validation set\n",
      "Got 841 / 1000 correct (84.10)\n",
      "Epoch 6, loss=0.1178\n",
      "Checking accuracy on validation set\n",
      "Got 813 / 1000 correct (81.30)\n",
      "Epoch 7, loss=0.1170\n",
      "Checking accuracy on validation set\n",
      "Got 802 / 1000 correct (80.20)\n",
      "Epoch 8, loss=0.1597\n",
      "Checking accuracy on validation set\n",
      "Got 829 / 1000 correct (82.90)\n",
      "Epoch 9, loss=0.2146\n",
      "Checking accuracy on validation set\n",
      "Got 827 / 1000 correct (82.70)\n",
      "best_acc: 0.841\n",
      "Checking accuracy on test set\n",
      "Got 8189 / 10000 correct (81.89)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8189"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "resnet = ResNet18()\n",
    "optimizer_resnet = optim.SGD(resnet.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "best_resnet = train_model(resnet, optimizer_resnet,10)\n",
    "check_accuracy(loader_test, best_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在Resnet18上训练10代，最好的验证集表现为84.1%，而在测试集上的表现为81.89%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch 0, loss=1.3632\n",
      "Checking accuracy on validation set\n",
      "Got 609 / 1000 correct (60.90)\n",
      "Epoch 1, loss=0.6613\n",
      "Checking accuracy on validation set\n",
      "Got 715 / 1000 correct (71.50)\n",
      "Epoch 2, loss=0.7622\n",
      "Checking accuracy on validation set\n",
      "Got 801 / 1000 correct (80.10)\n",
      "Epoch 3, loss=0.5876\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "Epoch 4, loss=0.6013\n",
      "Checking accuracy on validation set\n",
      "Got 826 / 1000 correct (82.60)\n",
      "Epoch 5, loss=0.5516\n",
      "Checking accuracy on validation set\n",
      "Got 824 / 1000 correct (82.40)\n",
      "Epoch 6, loss=0.2881\n",
      "Checking accuracy on validation set\n",
      "Got 862 / 1000 correct (86.20)\n",
      "Epoch 7, loss=0.2404\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "Epoch 8, loss=0.4172\n",
      "Checking accuracy on validation set\n",
      "Got 879 / 1000 correct (87.90)\n",
      "Epoch 9, loss=0.1719\n",
      "Checking accuracy on validation set\n",
      "Got 883 / 1000 correct (88.30)\n",
      "best_acc: 0.883\n",
      "Checking accuracy on test set\n",
      "Got 8627 / 10000 correct (86.27)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8627"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 应用数据增强\n",
    "cifar10_train = dset.CIFAR10('./dataset', train=True, download=True, transform=transform_aug)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "learning_rate = 1e-2\n",
    "resnet = ResNet18()\n",
    "optimizer_resnet = optim.SGD(resnet.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "best_resnet = train_model(resnet, optimizer_resnet,10)\n",
    "check_accuracy(loader_test, best_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加入数据增强，在Resnet18上训练10代，最好的验证集表现为88.3%，而在测试集上的表现为86.27%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch 0, loss=1.0704\n",
      "Checking accuracy on validation set\n",
      "Got 520 / 1000 correct (52.00)\n",
      "Epoch 1, loss=0.7277\n",
      "Checking accuracy on validation set\n",
      "Got 696 / 1000 correct (69.60)\n",
      "Epoch 2, loss=0.9168\n",
      "Checking accuracy on validation set\n",
      "Got 746 / 1000 correct (74.60)\n",
      "Epoch 3, loss=0.5203\n",
      "Checking accuracy on validation set\n",
      "Got 814 / 1000 correct (81.40)\n",
      "Epoch 4, loss=0.5422\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "Epoch 5, loss=0.5257\n",
      "Checking accuracy on validation set\n",
      "Got 823 / 1000 correct (82.30)\n",
      "Epoch 6, loss=0.5322\n",
      "Checking accuracy on validation set\n",
      "Got 869 / 1000 correct (86.90)\n",
      "Epoch 7, loss=0.2560\n",
      "Checking accuracy on validation set\n",
      "Got 847 / 1000 correct (84.70)\n",
      "Epoch 8, loss=0.2628\n",
      "Checking accuracy on validation set\n",
      "Got 868 / 1000 correct (86.80)\n",
      "Epoch 9, loss=0.1678\n",
      "Checking accuracy on validation set\n",
      "Got 865 / 1000 correct (86.50)\n",
      "best_acc: 0.869\n",
      "Checking accuracy on test set\n",
      "Got 8418 / 10000 correct (84.18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8418"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加大学习率\n",
    "cifar10_train = dset.CIFAR10('./dataset', train=True, download=True, transform=transform_aug)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "learning_rate = 1e-1\n",
    "resnet = ResNet18()\n",
    "optimizer_resnet = optim.SGD(resnet.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "best_resnet = train_model(resnet, optimizer_resnet,10)\n",
    "check_accuracy(loader_test, best_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加大学习率在10代训练后的表现并没有更好，最佳验证集准确率86.9%，测试集84.18%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch 0, loss=0.8779\n",
      "Checking accuracy on validation set\n",
      "Got 637 / 1000 correct (63.70)\n",
      "Epoch 1, loss=0.8793\n",
      "Checking accuracy on validation set\n",
      "Got 778 / 1000 correct (77.80)\n",
      "Epoch 2, loss=0.5103\n",
      "Checking accuracy on validation set\n",
      "Got 764 / 1000 correct (76.40)\n",
      "Epoch 3, loss=0.5943\n",
      "Checking accuracy on validation set\n",
      "Got 811 / 1000 correct (81.10)\n",
      "Epoch 4, loss=0.2430\n",
      "Checking accuracy on validation set\n",
      "Got 833 / 1000 correct (83.30)\n",
      "Epoch 5, loss=0.4615\n",
      "Checking accuracy on validation set\n",
      "Got 855 / 1000 correct (85.50)\n",
      "Epoch 6, loss=0.5494\n",
      "Checking accuracy on validation set\n",
      "Got 861 / 1000 correct (86.10)\n",
      "Epoch 7, loss=0.4116\n",
      "Checking accuracy on validation set\n",
      "Got 875 / 1000 correct (87.50)\n",
      "Epoch 8, loss=0.2203\n",
      "Checking accuracy on validation set\n",
      "Got 867 / 1000 correct (86.70)\n",
      "Epoch 9, loss=0.3387\n",
      "Checking accuracy on validation set\n",
      "Got 868 / 1000 correct (86.80)\n",
      "Epoch 10, loss=0.2616\n",
      "Checking accuracy on validation set\n",
      "Got 865 / 1000 correct (86.50)\n",
      "Epoch 11, loss=0.2483\n",
      "Checking accuracy on validation set\n",
      "Got 888 / 1000 correct (88.80)\n",
      "Epoch 12, loss=0.2430\n",
      "Checking accuracy on validation set\n",
      "Got 886 / 1000 correct (88.60)\n",
      "Epoch 13, loss=0.1948\n",
      "Checking accuracy on validation set\n",
      "Got 883 / 1000 correct (88.30)\n",
      "Epoch 14, loss=0.2243\n",
      "Checking accuracy on validation set\n",
      "Got 907 / 1000 correct (90.70)\n",
      "Epoch 15, loss=0.2063\n",
      "Checking accuracy on validation set\n",
      "Got 930 / 1000 correct (93.00)\n",
      "Epoch 16, loss=0.1145\n",
      "Checking accuracy on validation set\n",
      "Got 929 / 1000 correct (92.90)\n",
      "Epoch 17, loss=0.0595\n",
      "Checking accuracy on validation set\n",
      "Got 933 / 1000 correct (93.30)\n",
      "Epoch 18, loss=0.1242\n",
      "Checking accuracy on validation set\n",
      "Got 928 / 1000 correct (92.80)\n",
      "Epoch 19, loss=0.1523\n",
      "Checking accuracy on validation set\n",
      "Got 931 / 1000 correct (93.10)\n",
      "Epoch 20, loss=0.0391\n",
      "Checking accuracy on validation set\n",
      "Got 926 / 1000 correct (92.60)\n",
      "Epoch 21, loss=0.1844\n",
      "Checking accuracy on validation set\n",
      "Got 930 / 1000 correct (93.00)\n",
      "Epoch 22, loss=0.1384\n",
      "Checking accuracy on validation set\n",
      "Got 922 / 1000 correct (92.20)\n",
      "Epoch 23, loss=0.2353\n",
      "Checking accuracy on validation set\n",
      "Got 926 / 1000 correct (92.60)\n",
      "Epoch 24, loss=0.0820\n",
      "Checking accuracy on validation set\n",
      "Got 928 / 1000 correct (92.80)\n",
      "Epoch 25, loss=0.1456\n",
      "Checking accuracy on validation set\n",
      "Got 928 / 1000 correct (92.80)\n",
      "Epoch 26, loss=0.0522\n",
      "Checking accuracy on validation set\n",
      "Got 927 / 1000 correct (92.70)\n",
      "Epoch 27, loss=0.0125\n",
      "Checking accuracy on validation set\n",
      "Got 927 / 1000 correct (92.70)\n",
      "Epoch 28, loss=0.0512\n",
      "Checking accuracy on validation set\n",
      "Got 929 / 1000 correct (92.90)\n",
      "Epoch 29, loss=0.1311\n",
      "Checking accuracy on validation set\n",
      "Got 933 / 1000 correct (93.30)\n",
      "Epoch 30, loss=0.1153\n",
      "Checking accuracy on validation set\n",
      "Got 931 / 1000 correct (93.10)\n",
      "Epoch 31, loss=0.0327\n",
      "Checking accuracy on validation set\n",
      "Got 933 / 1000 correct (93.30)\n",
      "Epoch 32, loss=0.0463\n",
      "Checking accuracy on validation set\n",
      "Got 932 / 1000 correct (93.20)\n",
      "Epoch 33, loss=0.0249\n",
      "Checking accuracy on validation set\n",
      "Got 929 / 1000 correct (92.90)\n",
      "Epoch 34, loss=0.0579\n",
      "Checking accuracy on validation set\n",
      "Got 931 / 1000 correct (93.10)\n",
      "Epoch 35, loss=0.0827\n",
      "Checking accuracy on validation set\n",
      "Got 933 / 1000 correct (93.30)\n",
      "Epoch 36, loss=0.0606\n",
      "Checking accuracy on validation set\n",
      "Got 933 / 1000 correct (93.30)\n",
      "Epoch 37, loss=0.0565\n",
      "Checking accuracy on validation set\n",
      "Got 934 / 1000 correct (93.40)\n",
      "Epoch 38, loss=0.0604\n",
      "Checking accuracy on validation set\n",
      "Got 927 / 1000 correct (92.70)\n",
      "Epoch 39, loss=0.0620\n",
      "Checking accuracy on validation set\n",
      "Got 932 / 1000 correct (93.20)\n",
      "Epoch 40, loss=0.0122\n",
      "Checking accuracy on validation set\n",
      "Got 930 / 1000 correct (93.00)\n",
      "Epoch 41, loss=0.0490\n",
      "Checking accuracy on validation set\n",
      "Got 932 / 1000 correct (93.20)\n",
      "Epoch 42, loss=0.0855\n",
      "Checking accuracy on validation set\n",
      "Got 930 / 1000 correct (93.00)\n",
      "Epoch 43, loss=0.1429\n",
      "Checking accuracy on validation set\n",
      "Got 927 / 1000 correct (92.70)\n",
      "Epoch 44, loss=0.0630\n",
      "Checking accuracy on validation set\n",
      "Got 932 / 1000 correct (93.20)\n",
      "Epoch 45, loss=0.1685\n",
      "Checking accuracy on validation set\n",
      "Got 930 / 1000 correct (93.00)\n",
      "Epoch 46, loss=0.0317\n",
      "Checking accuracy on validation set\n",
      "Got 929 / 1000 correct (92.90)\n",
      "Epoch 47, loss=0.0828\n",
      "Checking accuracy on validation set\n",
      "Got 930 / 1000 correct (93.00)\n",
      "Epoch 48, loss=0.0214\n",
      "Checking accuracy on validation set\n",
      "Got 934 / 1000 correct (93.40)\n",
      "Epoch 49, loss=0.1193\n",
      "Checking accuracy on validation set\n",
      "Got 930 / 1000 correct (93.00)\n",
      "best_acc: 0.934\n",
      "Checking accuracy on test set\n",
      "Got 9160 / 10000 correct (91.60)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.916"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练更多代数，并应用学习率衰减\n",
    "cifar10_train = dset.CIFAR10('./dataset', train=True, download=True, transform=transform_aug)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "learning_rate = 1e-2\n",
    "resnet = ResNet18()\n",
    "optimizer_resnet = optim.SGD(resnet.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "scheduler = lr_scheduler.StepLR(optimizer_resnet, step_size=15,gamma=0.1)\n",
    "best_resnet = train_model(resnet, optimizer_resnet,50, scheduler)\n",
    "check_accuracy(loader_test, best_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增加训练代数并且应用学习率衰减后，最佳验证集准确率93.4%，测试集91.6%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 结论\n",
    "通过构建不同复杂度的网络，使得在cifar-10测试集上的表现从46.85%提升到了91.6%。并穿插了数据增强，学习率调整等内容。如果希望继续提升模型表现，可以考虑加入正则化，训练更多的代数，并且尝试更细粒度的学习率调整，也可以尝试其他经典网络结构。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
